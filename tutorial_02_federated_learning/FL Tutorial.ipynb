{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Federated Learning Hands-On\n",
    "\n",
    "In this tutorial, you will convert a traditional ML training pipeline into a federated one.\n",
    "You will also learn about the peculiarities of the threat model in FL that enable more sophisticated backdoor attacks than in centralized ML.\n",
    "Finally, you will be encouraged to come up with your own defense against such backdoor attacks.\n",
    "\n",
    "_Note:_ All tasks can be solved on a CPU within an acceptable runtime.\n",
    "If you have an NVIDIA GPU or are running on a Mac that supports MPS, the following snippet will enable GPU acceleration.\n",
    "If you want to avoid having to download the dataset during the tutorial session, run the following cell before the session."
   ],
   "id": "ff4a9e1e78d0f140"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Please make sure that you can execute the following lines without error\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "import random\n",
    "from typing import List, OrderedDict, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "mps_available = getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available()\n",
    "\n",
    "if cuda_available:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif mps_available:\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS is available. Using Apple Silicon GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU found. Falling back to CPU.\")\n",
    "\n",
    "# For reproducibility\n",
    "reproducible = True\n",
    "\n",
    "if reproducible:\n",
    "    seed = 42\n",
    "    from torch.backends import cudnn\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.mps.manual_seed(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.enabled = True\n",
    "    cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# Summary\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Download the dataset already\n",
    "torchvision.datasets.MNIST(root=\"./data\", train=True, download=True)\n",
    "torchvision.datasets.MNIST(root=\"./data\", train=False, download=True)"
   ],
   "id": "380065b260bcad4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Basic ML training\n",
    "\n",
    "To build a foundation for the following FL tasks, we start with a standard centralized ML training pipeline that allows us to train a simple classifier for the MNIST dataset, which can correctly label hand-written digits."
   ],
   "id": "49cfb0152bff4fc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We use a very simple CNN with only roughly 14k trainable parameters\n",
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 8, 3)\n",
    "        self.fc1_input_size = ((28 - 4) // 2 - 2) // 2\n",
    "        self.fc1 = nn.Linear(8 * self.fc1_input_size ** 2, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)        # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # Logits (use CrossEntropyLoss)\n",
    "        return x\n",
    "\n",
    "model = MNISTClassifier().to(device)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "\n",
    "print(f\"Total number of trainable parameters: {params}\")"
   ],
   "id": "9f53ae1f8fc1f2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We now load the dataset, define data normalization and some additional augmentations to increase generalizability, and define the dataloader instances\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(28, 4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307), (0.3081)),\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307), (0.3081)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=train_transforms, download=True)\n",
    "test_set = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=test_transforms, download=True)\n",
    "\n",
    "# Build the dataloader instances\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1024, shuffle=False, num_workers=2)\n",
    "\n",
    "# To get an impression of the data, let's visualize 25 of the images\n",
    "fig, axs = plt.subplots(5, 5)\n",
    "\n",
    "imgs, labels = next(iter(test_loader))\n",
    "for i in range(25):\n",
    "    im = axs[i // 5, i % 5].imshow((imgs[i].permute(1, 2, 0) + 1) / 2, cmap=\"gray\")\n",
    "    axs[i // 5, i % 5].axis('off')\n",
    "    axs[i // 5, i % 5].set_title(labels[i].item())\n",
    "    axs[i // 5, i % 5].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b363c50df83ad29f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we define two methods `process_batch` and `test`.",
   "id": "ef472df1d47b7b55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_batch(\n",
    "    batch: Tuple[torch.Tensor, torch.Tensor],\n",
    "    model: nn.Module,\n",
    "    train: bool,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: Optional[optim.Optimizer] = None\n",
    ") -> Tuple[float, int, int]:\n",
    "    \"\"\"\n",
    "    Processes a single batch of data through the model.\n",
    "\n",
    "    Args:\n",
    "        batch (Tuple[Tensor, Tensor]): A tuple containing input data and corresponding labels.\n",
    "        model (nn.Module): The neural network model.\n",
    "        train (bool): If True, performs a training step. Otherwise, evaluation only.\n",
    "        criterion (nn.Module): Loss function to compute the loss.\n",
    "        optimizer (Optional[Optimizer]): Optimizer used for training, required if train is True.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, int, int]: The loss value, number of correctly predicted samples, and total samples.\n",
    "    \"\"\"\n",
    "    inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    if train:\n",
    "        assert optimizer is not None, \"Optimizer must be provided in training mode.\"\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss.item(), correct, total\n",
    "\n",
    "def test(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    criterion: nn.Module\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the model on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "        data_loader (DataLoader): DataLoader providing the test dataset.\n",
    "        criterion (nn.Module): Loss function used for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: Average loss and accuracy (in percentage).\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss, correct, total = 0.0, 0, 0\n",
    "        for inputs, labels in data_loader:\n",
    "            batch_loss, batch_correct, batch_total = process_batch(\n",
    "                (inputs, labels), model, False, criterion\n",
    "            )\n",
    "            loss += batch_loss\n",
    "            total += batch_total\n",
    "            correct += batch_correct\n",
    "    return loss / len(data_loader), 100 * correct / total"
   ],
   "id": "19240b0a461d1a77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "With these helper functions defined, we now train the model for 20 epochs using simple SGD with a learning rate of $\\eta=0.01$, momentum of $\\mu=0.9$, weight decay of $\\lambda = 0.0001$, and cross entropy as the loss function.\n",
    "We report the train and test loss and accuracy in each round and visualize them after training concludes."
   ],
   "id": "db0d5ae46a0b0c46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define hyperparameters\n",
    "epochs = 20\n",
    "lr = 0.01\n",
    "mu = 0.9\n",
    "weight_decay = 0.0001\n",
    "\n",
    "# Instantiate the model, loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=mu, weight_decay=weight_decay)\n",
    "\n",
    "train_loss_list_ml = []\n",
    "train_acc_list_ml = []\n",
    "test_loss_list_ml = []\n",
    "test_acc_list_ml = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    # Train for one epoch\n",
    "    for inputs, labels in train_loader:\n",
    "        batch_loss, batch_correct, batch_total = process_batch((inputs, labels), model, True, criterion, optimizer)\n",
    "        loss += batch_loss\n",
    "        correct += batch_correct\n",
    "        total += batch_total\n",
    "\n",
    "    train_loss = loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    train_loss_list_ml.append(train_loss)\n",
    "    train_acc_list_ml.append(train_acc)\n",
    "\n",
    "    # Compute test loss\n",
    "    test_loss, test_acc = test(model, test_loader, criterion)\n",
    "    test_loss_list_ml.append(test_loss)\n",
    "    test_acc_list_ml.append(test_acc)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f} %')\n",
    "    print(f'Epoch {epoch + 1}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f} %')\n",
    "    print()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].plot(train_loss_list_ml, label=\"Train Loss\")\n",
    "axs[0].plot(test_loss_list_ml, label='Test Loss')\n",
    "axs[0].legend()\n",
    "axs[0].grid()\n",
    "\n",
    "axs[1].plot(train_acc_list_ml, label='Train Acc')\n",
    "axs[1].plot(test_acc_list_ml, label='Test Acc')\n",
    "axs[1].legend()\n",
    "axs[1].grid()\n",
    "plt.show()\n"
   ],
   "id": "29e2b1de042619c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Let's go federated!\n",
    "\n",
    "After this refresher on basic machine learning, we want to take it to the next level with federated learning!\n",
    "\n",
    "### Recap: FL\n",
    "\n",
    "Federated Learning is a form of decentralized machine learning where a central server coordinates the training of $N$ clients $i \\in [0, \\dots, N - 1]$ that each possess a local dataset $\\mathcal D_i$ of size $n_i$.\n",
    "Note that the IIDness assumption that is commonly used in ML is not assumed in FL, i.e., it is assumed that the data is distributed in a non-IID fashion between the clients.\n",
    "For simulation purposes, this is often realized by class-wise sampling according to a Dirichlet distribution.\n",
    "\n",
    "During a single (global) round of FL, a set $C^t$ of $M$ clients are selected to\n",
    "\n",
    "1. receive the current global model $\\theta^t$\n",
    "2. train on it using their local dataset for $E$ local training epochs\n",
    "3. return their locally trained version of the model $\\theta^{t+1}_i$\n",
    "\n",
    "The central server then uses an _aggregation rule_ (in the simplest form: Federated Averaging (FedAvg), i.e., simple weighted averaging per-parameter, cf. \"Communication-Efficient Learning of Deep Networks from Decentralized Data\" by McMahan et al. (AISTATS 2017)) on all sent models to create the global model of the next global round:\n",
    "\n",
    "$$\\theta^{t+1} = \\sum_{i \\in C^t}{\\frac{n_i}{\\sum_{j \\in C^t}{n_i}} \\theta^{t+1}_i}$$\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Using the given ML training pipeline as a basis, let's now adapt it to a federated setting.\n",
    "We assume that there are $N=100$ clients that each have a non-IID share of the whole dataset and that $M=10$ clients are selected per round to train for $E=2$ local training epochs.\n",
    "\n",
    "First, we are splitting the dataset label-wise for simulation purposes according to a Dirichlet distribution with hyperparameter $\\alpha = 0.9$:"
   ],
   "id": "f41a8e2dfbe67915"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "N = 100 # number of clients in the system\n",
    "M = 10 # number of clients per round\n",
    "dirichlet_alpha = 0.9\n",
    "E = 2 # number of local training epochs\n",
    "\n",
    "def split_dataset_dirichlet(dataset, num_clients=100, alpha=0.9):\n",
    "    label_indices = defaultdict(list)\n",
    "\n",
    "    # Step 1: Group indices by class\n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        label_indices[label].append(idx)\n",
    "\n",
    "    # Step 2: For each class, distribute indices to clients using Dirichlet distribution\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(10):  # MNIST has 10 classes\n",
    "        np.random.shuffle(label_indices[c])\n",
    "        proportions = np.random.dirichlet(alpha=[alpha]*num_clients)\n",
    "        proportions = (np.cumsum(proportions) * len(label_indices[c])).astype(int)[:-1]\n",
    "        split_indices = np.split(label_indices[c], proportions)\n",
    "        for client_id, idxs in enumerate(split_indices):\n",
    "            client_indices[client_id].extend(idxs)\n",
    "\n",
    "    return client_indices\n",
    "\n",
    "client_indices = split_dataset_dirichlet(train_set, num_clients=N, alpha=dirichlet_alpha)\n",
    "\n",
    "# Build dataloaders for each client\n",
    "client_loaders = []\n",
    "for indices in client_indices:\n",
    "    client_subset = torch.utils.data.Subset(copy.deepcopy(train_set), indices)\n",
    "    loader = torch.utils.data.DataLoader(client_subset, batch_size=64, shuffle=True, num_workers=0, drop_last=True)\n",
    "    client_loaders.append(loader)"
   ],
   "id": "74acd1a3ff00dc79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Further, we define some utility functions to extract parameters from a model as a list of numpy arrays and to re-build a model from such a parameter list:"
   ],
   "id": "76bb4113d5286f14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_variable_params(model: nn.Module) -> List[str]:\n",
    "    \"\"\"\n",
    "    Retrieves the names of model parameters that should be included in training,\n",
    "    excluding non-trainable parameters such as 'num_batches_tracked'.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model from which to extract parameter names.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of parameter names to include.\n",
    "    \"\"\"\n",
    "    return list(filter(lambda name: 'num_batches_tracked' not in name, model.state_dict().keys()))\n",
    "\n",
    "\n",
    "def get_parameters(model: nn.Module) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts and returns the model parameters as NumPy arrays, excluding\n",
    "    non-variable buffers like 'num_batches_tracked'.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to extract parameters from.\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: A list of NumPy arrays representing the model's parameters.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        params = get_variable_params(model)\n",
    "        state_dict = model.state_dict()\n",
    "        return [state_dict[name].cpu().numpy() for name in params]\n",
    "\n",
    "\n",
    "def build_model(parameters: List[np.ndarray]) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Builds a new MNISTClassifier model and loads it with the provided parameters.\n",
    "\n",
    "    Args:\n",
    "        parameters (List[np.ndarray]): A list of NumPy arrays representing model parameters.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: A PyTorch model initialized with the given parameters.\n",
    "    \"\"\"\n",
    "    model = MNISTClassifier().to(device)\n",
    "    params_dict = zip(get_variable_params(model), parameters)\n",
    "    state_dict = OrderedDict({k: torch.as_tensor(v, device=device) for k, v in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    return model"
   ],
   "id": "bd0a4767c71a8e55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Now, define the server-side aggregation rule:"
   ],
   "id": "98bbf4a30da229e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def agg(\n",
    "    global_params: List[np.ndarray],\n",
    "    updates: List[List[np.ndarray]],\n",
    "    num_datapoints: List[int]\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Aggregates local model updates using a weighted average based on the number of data points.\n",
    "\n",
    "    Args:\n",
    "        global_params (List[np.ndarray]): The current global model parameters.\n",
    "        updates (List[List[np.ndarray]]): A list of local model parameter updates from each client.\n",
    "        num_datapoints (List[int]): A list indicating the number of data points used by each client.\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: The updated global model parameters after aggregation.\n",
    "    \"\"\"\n",
    "    pass # TODO\n",
    "\n",
    "    return global_params"
   ],
   "id": "676461639cb036f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "With this set, we can now define the FL training procedure:"
   ],
   "id": "2b3cfee0b5b2da0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def single_client_round(\n",
    "    global_model_params: List[np.ndarray],\n",
    "    client_id: int,\n",
    "    round: int\n",
    ") -> Tuple[List[np.ndarray], int]:\n",
    "    \"\"\"\n",
    "    Trains a single client model on its local data for E local training epochs and returns updated parameters.\n",
    "\n",
    "    Args:\n",
    "        global_model_params (List[np.ndarray]): Global model parameters before the round.\n",
    "        client_id (int): ID of the client to train.\n",
    "        round (int): Current training round index (used for logging or tracking).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[np.ndarray], int]: Updated model parameters and number of local datapoints.\n",
    "    \"\"\"\n",
    "    pass # TODO\n",
    "\n",
    "    return get_parameters(model), num_datapoints\n",
    "\n",
    "\n",
    "def single_round(\n",
    "    global_model_params: List[np.ndarray],\n",
    "    round: int\n",
    ") -> Tuple[List[np.ndarray], float, float]:\n",
    "    \"\"\"\n",
    "    Performs a single federated learning round with a subset of clients.\n",
    "\n",
    "    Args:\n",
    "        global_model_params (List[np.ndarray]): Global model parameters before the round.\n",
    "        round (int): Current training round index.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[np.ndarray], float, float]: Updated global model parameters, test loss, and test accuracy.\n",
    "    \"\"\"\n",
    "    clients = random.sample(list(range(N)), M)\n",
    "\n",
    "    pass # TODO\n",
    "\n",
    "    return new_global_model_params, test_loss, test_acc\n",
    "\n",
    "\n",
    "def fl_training(num_rounds: int) -> Tuple[List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Runs the federated training process for a specified number of rounds.\n",
    "\n",
    "    Args:\n",
    "        num_rounds (int): Total number of federated learning rounds.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[float], List[float]]: Lists of test losses and accuracies over the rounds.\n",
    "    \"\"\"\n",
    "    pass # TODO\n",
    "\n",
    "    return test_loss_list_fl, test_acc_list_fl"
   ],
   "id": "84d59980a9155e9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, train the MNIST classifier using FL for 50 global rounds with $E=2$ local training epochs. Record test set accuracy and plot the accuracy curve of the previous ML training and the FL training in one plot to allow comparability.\n",
    "\n",
    "_Note:_ In most cases, HFL requires higher learning rates than ML. Set $\\eta=0.1$ and keep all other hyperparameters unchanged."
   ],
   "id": "6e377dbe04e09d93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_rounds = 50\n",
    "lr = 0.1 # Update learning rate\n",
    "\n",
    "test_loss_list_fl, test_acc_list_fl = fl_training(num_rounds)\n",
    "\n",
    "plt.plot(test_acc_list_fl, label='Test accuracy (FL)')\n",
    "plt.plot(test_acc_list_ml, label='Test accuracy (ML)')\n",
    "plt.legend()\n",
    "plt.xlabel('round')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "336990c987ff0639",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can observe that we can achieve similar accuracies with FL as with regular ML.\n",
    "\n",
    "_Note_: Since we only train on an $M/N$ fraction of the dataset per round, one round of ML training corresponds to $~N/M$ rounds of FL training in terms of the number of data points the model has seen. That means, for $N = 100, M = 10$, the accuracies of ML in round 5 and FL in round 50 should be roughly comparable - which they are."
   ],
   "id": "94e1fd73fac6bead"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## But what if...?\n",
    "\n",
    "In HFL, we outsource the training process to untrusted clients.\n",
    "What if one or more of these clients has malicious intentions and tries to introduce unintended, stealthy behavior into the model?\n",
    "For example, consider generative models and the potential introduction of racial biases or faulty classifiers in security-critical applications, such as traffic sign recognition, which malfunction under certain circumstances.\n",
    "\n",
    "Now, we want to test how a malicious client could introduce a so-called _backdoor_ into the global model.\n",
    "A backdoor attacker has a two-fold goal:\n",
    "\n",
    "1. They want to maintain high main task accuracy (MTA), i.e., the model's accuracy on the clean dataset, high to ensure _utility_ and stealthiness.\n",
    "2. All inputs exhibiting the trigger must be successfully misclassified as the _target class_, measured by the backdoor accuracy (BDA).\n",
    "\n",
    "To achieve that goal, an attacker could poison a $\\rho \\in [0, 1]$ fraction of its local dataset to exhibit the trigger and be mislabeled as the target class.\n",
    "$\\rho$ is a hyperparameter that tunes the importance of the two attack goals.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "In the following, your task is to slip into the role of an attacker and try to backdoor the global model using only your local data.\n",
    "The trigger pattern we are using is a pixel graphic of the [CASAfant](https://casa.rub.de/en/news/social-media) and your target class is class 1.\n",
    "Assume that $10\\%$ of all clients are malicious and that these malicious clients launch the attack whenever they are selected for training, using a hyperparameter $\\rho=0.2$."
   ],
   "id": "b6e6941745cbef67"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As a first step, we now implement helper functions to poison a batch of data and to measure the BDA.",
   "id": "85fb1eb4efff3b4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CASAfant as a pixel pattern (fist component of the tuple are the x-coordinates that are to be set to white while the second one resembles the y-coordinates)\n",
    "ELEPHANT = ([3, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 3, 4, 1, 2, 3, 4, 5, 5, 4],\n",
    "            [0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 8])\n",
    "\n",
    "malicious_fraction = 0.1\n",
    "poisoned_client_ids = list(range(int(N * malicious_fraction)))\n",
    "\n",
    "poisoned_fraction = 0.2\n",
    "\n",
    "def make_poisoned_batch(\n",
    "    batch: Tuple[Tensor, Tensor],\n",
    "    target_class: int,\n",
    "    poisoned_frac: float = 0.2\n",
    ") -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Poisons a fraction of the given batch by modifying the input and changing the label.\n",
    "\n",
    "    Args:\n",
    "        batch (Tuple[Tensor, Tensor]): A batch of (inputs, labels).\n",
    "        target_class (int): The target class to assign to poisoned samples.\n",
    "        poisoned_frac (float, optional): Fraction of the batch to poison. Defaults to 0.2.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Tensor, Tensor]: The poisoned inputs and labels.\n",
    "    \"\"\"\n",
    "    inputs, labels = batch\n",
    "    poisoned_dps = int(poisoned_frac * len(labels))\n",
    "    inputs[:poisoned_dps, 0, ELEPHANT[0], ELEPHANT[1]] = 1  # Trigger injection\n",
    "    labels[:poisoned_dps] = target_class\n",
    "    return inputs, labels\n",
    "\n",
    "# Let's visualize a few samples\n",
    "fig, axs = plt.subplots(5, 5)\n",
    "\n",
    "imgs, labels = next(iter(test_loader))\n",
    "imgs, labels = make_poisoned_batch((imgs, labels), 8, 1)\n",
    "for i in range(25):\n",
    "    im = axs[i // 5, i % 5].imshow((imgs[i].permute(1, 2, 0) + 1) / 2, cmap=\"gray\")\n",
    "    axs[i // 5, i % 5].axis('off')\n",
    "    axs[i // 5, i % 5].set_title(labels[i].item())\n",
    "    axs[i // 5, i % 5].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "def test_bda(\n",
    "    model: torch.nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the backdoor accuracy (BDA) of a model using fully poisoned test data.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to evaluate.\n",
    "        data_loader (DataLoader): Data loader providing clean test samples to poison.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: Average loss and backdoor accuracy (% of inputs misclassified as target).\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss, correct, total = 0.0, 0, 0\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = make_poisoned_batch((inputs, labels), 0, poisoned_frac=1)\n",
    "            batch_loss, batch_correct, batch_total = process_batch((inputs, labels), model, False, criterion)\n",
    "            loss += batch_loss\n",
    "            total += batch_total\n",
    "            correct += batch_correct\n",
    "    return loss / len(data_loader), 100 * correct / total"
   ],
   "id": "85c7546fcc065605",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Now, we redefine the `single_client_round()` method from before to poison all batches before calling `process_batch` if the `client_id` belongs to the malicious clients.\n",
    "Further, `single_round()` and `fl_training()` are modified to measure and return the BDA as well."
   ],
   "id": "38bb4e903c203b81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def single_client_round(\n",
    "    global_model_params: List[np.ndarray],\n",
    "    client_id: int,\n",
    "    round: int\n",
    ") -> Tuple[List[np.ndarray], int]:\n",
    "    \"\"\"\n",
    "    Executes a single local training round for a client.\n",
    "\n",
    "    If the client is in `poisoned_client_ids`, poisons the input batches using `make_poisoned_batch`.\n",
    "\n",
    "    Args:\n",
    "        global_model_params (List[np.ndarray]): Parameters of the current global model.\n",
    "        client_id (int): Index of the client performing local training.\n",
    "        round (int): The current global round (used for logging/debugging).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[np.ndarray], int]: Updated model parameters and number of datapoints used.\n",
    "    \"\"\"\n",
    "    if client_id in poisoned_client_ids:\n",
    "        print(f'Attacker {client_id} is active!')\n",
    "\n",
    "    pass # TODO\n",
    "\n",
    "    return get_parameters(model), num_datapoints\n",
    "\n",
    "\n",
    "def single_round(\n",
    "    global_model_params: List[np.ndarray],\n",
    "    round: int\n",
    ") -> Tuple[List[np.ndarray], float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Executes one federated learning round with possible malicious clients.\n",
    "\n",
    "    Extends the clean version by additionally evaluating the model on poisoned test data\n",
    "    using `test_bda` for backdoor detection.\n",
    "\n",
    "    Args:\n",
    "        global_model_params (List[np.ndarray]): Current global model parameters.\n",
    "        round (int): Index of the current round.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "            - Updated global model parameters\n",
    "            - Clean test loss\n",
    "            - Clean test accuracy\n",
    "            - Backdoor test loss\n",
    "            - Backdoor test accuracy\n",
    "    \"\"\"\n",
    "    clients = random.sample(list(range(N)), M)\n",
    "\n",
    "    pass # TODO\n",
    "\n",
    "    return new_global_model_params, test_loss_clean, test_acc_clean, test_loss_backdoor, test_acc_backdoor\n",
    "\n",
    "\n",
    "def fl_training(num_rounds: int) -> Tuple[List[float], List[float], List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Runs the full federated training process across multiple rounds.\n",
    "\n",
    "    Tracks both clean and backdoor performance metrics for each round.\n",
    "\n",
    "    Args:\n",
    "        num_rounds (int): Total number of federated learning rounds.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing four lists (one per round):\n",
    "            - Clean test loss\n",
    "            - Clean test accuracy\n",
    "            - Backdoor test loss\n",
    "            - Backdoor test accuracy\n",
    "    \"\"\"\n",
    "    pass # TODO\n",
    "\n",
    "    return test_loss_list_fl_clean, test_acc_list_fl_clean, test_loss_list_fl_backdoor, test_acc_list_fl_backdoor"
   ],
   "id": "6e079b0efd57ec49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, repeat the FL training from before and plot MTA and BDA in a single plot.",
   "id": "b27ef67fdd293c0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_loss_list_fl_clean, test_acc_list_fl_clean, test_loss_list_fl_backdoor, test_acc_list_fl_backdoor = fl_training(num_rounds)\n",
    "\n",
    "plt.plot(test_acc_list_fl_clean, label='Clean Accuracy')\n",
    "plt.plot(test_acc_list_fl_backdoor, label='Backdoor Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('round')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "1c5379d74306acf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## More advanced Attacks\n",
    "\n",
    "We have now explored a basic data poisoning attack first mentioned in the paper \"BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain\" by Gu et al. (Arxiv, 2017).\n",
    "This attack is also possible in regular, centralized machine learning — an adversary can provide poisoned data to an entity training an ML model, thereby injecting a backdoor.\n",
    "In HFL, however, we must consider an additional threat: A so-called _model poisoning attacker_.\n",
    "This concept was introduced in \"How to Backdoor Federated Learning\" by Bagdasaryan et al. (AISTATS, 2020), and it is based on the following idea:\n",
    "\n",
    "In HFL, the only communication between the coordinating server and the clients is the exchange of model weights. Thus, in principle, clients can _completely control their local training process_, i.e., modify training hyperparameters or return parameters obtained in a completely different way.\n",
    "\n",
    "This gives rise to a simple but very powerful attack - the _Model Replacement Attack (MRA)_ (Bagdasaryan et al., AISTATS 2020):\n",
    "\n",
    "The core idea is that an adversary can artificially _scale-up_ its local model parameters before sending them to the server, thereby increasing its influence on the global model.\n",
    "The exact formula for computing the return value of a malicious client is\n",
    "\n",
    "$$\\theta^{t+1}_m = \\gamma \\cdot (\\theta^* - \\theta^{t}) + \\theta^t$$\n",
    "\n",
    "where $\\gamma$ is a scaling factor, $\\gamma = M$ causes full model replacement, $\\theta^*$ is the backdoored model, and $\\theta^t$ is the global model from the previous round.\n",
    "\n",
    "Your task is to now implement this attack and test its capabilities with only one malicious client active.\n",
    "To this end, re-define `single_client_round()` again to implement the malicious behavior and repeat the experiment from before.\n",
    "\n",
    "_Tip:_ This attack is most effective when the model is close to convergence. The easiest way to do so is to only allow the adversary to be active from the 20th round onward."
   ],
   "id": "2fa0ae44a6c80865"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scaling_factor = M\n",
    "\n",
    "malicious_fraction = 0.01\n",
    "poisoned_client_ids = list(range(int(N * malicious_fraction)))\n",
    "\n",
    "def single_client_round(\n",
    "    global_model_params: List[np.ndarray],\n",
    "    client_id: int,\n",
    "    round: int\n",
    ") -> Tuple[List[np.ndarray], int]:\n",
    "    \"\"\"\n",
    "    Executes a local training round for a single client with optional model replacement attack.\n",
    "\n",
    "    Behavior:\n",
    "    - For benign clients or rounds ≤ 20: clean local training.\n",
    "    - For poisoned clients in round > 20:\n",
    "        - Trains on poisoned data using `make_poisoned_batch`.\n",
    "        - Applies model replacement attack by amplifying the update via `scaling_factor`.\n",
    "\n",
    "    Args:\n",
    "        global_model_params (List[np.ndarray]): Current global model parameters.\n",
    "        client_id (int): Index of the client.\n",
    "        round (int): Current global round.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[np.ndarray], int]: New client model parameters (possibly manipulated) and number of datapoints used.\n",
    "    \"\"\"\n",
    "    if client_id in poisoned_client_ids and round >= 20:\n",
    "        print(f'Attacker {client_id} is active!')\n",
    "\n",
    "    pass # TODO\n",
    "\n",
    "    return parameters, num_datapoints\n",
    "\n",
    "test_loss_list_fl_clean, test_acc_list_fl_clean, test_loss_list_fl_backdoor, test_acc_list_fl_backdoor = fl_training(num_rounds)\n",
    "\n",
    "plt.plot(test_acc_list_fl_clean, label='Clean Accuracy')\n",
    "plt.plot(test_acc_list_fl_backdoor, label='Backdoor Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('round')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "62714ca38a523ade",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Get creative: A simple defense\n",
    "\n",
    "In FL, defenses against such backdoor attacks are mostly realized as variations of the server-side aggregation rule.\n",
    "\n",
    "For the final task, you can get creative and devise your own defense against the model replacement attack we explored earlier.\n",
    "\n",
    "Think about it:\n",
    "\n",
    "- What would be the easiest way to counteract this specific attack?\n",
    "- Which properties distinguish the malicious update from benign updates on the server?\n",
    "- Do you have any ideas on how to modify the aggregation rule to counteract this behavior?\n",
    "\n",
    "Try implementing your approach by modifying and redefining your `agg()` function below to see what you can achieve."
   ],
   "id": "e09142cb0913ec78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### One solution: Norm Clipping\n",
    "norm_bound = 2.5\n",
    "\n",
    "def agg(\n",
    "    global_params: List[np.ndarray],\n",
    "    updates: List[List[np.ndarray]],\n",
    "    nums_dps: List[int]\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Aggregates local model updates using a weighted average based on the number of data points.\n",
    "\n",
    "    Args:\n",
    "        global_params (List[np.ndarray]): The current global model parameters.\n",
    "        updates (List[List[np.ndarray]]): A list of local model parameter updates from each client.\n",
    "        num_datapoints (List[int]): A list indicating the number of data points used by each client.\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: The updated global model parameters after aggregation.\n",
    "    \"\"\"\n",
    "    pass # TODO\n",
    "\n",
    "    return global_params\n",
    "\n",
    "\n",
    "# Test your defense\n",
    "test_loss_list_fl_clean, test_acc_list_fl_clean, test_loss_list_fl_backdoor, test_acc_list_fl_backdoor = fl_training(num_rounds)\n",
    "\n",
    "plt.plot(test_acc_list_fl_clean, label='Clean Accuracy')\n",
    "plt.plot(test_acc_list_fl_backdoor, label='Backdoor Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('round')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "acfc694be7461287",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
